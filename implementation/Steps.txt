High-level summary of how the planner works (from the file) 

llm_planner

plan(...) is the entrypoint. It tries a fast path first (_try_fast_path_routing). If not matched, it builds a large LLM prompt (_build_prompt) and calls the planner LLM.

The LLM must return a JSON plan. That JSON is parsed (_parse_json) and sanitized (_sanitize_plan_payload) and validated by PlanGatekeeper.

The returned raw steps are then post-processed in _post_process_steps where the code:

canonicalizes tools,

applies tool policies,

adds/removes agents via a set of _needs_* helpers,

reorders by priority (_reorder_by_priority),

enforces single-agent heuristics for short/simple prompts,

and applies special-case reductions (e.g., proposal queries drop finance_agent).

If anything fails, heuristics (_build_keyword_plan) or fallback (_build_fallback_plan) are used.

2) Root causes of the behaviors you observed (why wrong agent choices happen) 

llm_planner

A. Over-eager fast path rules

_try_fast_path_routing contains short-length heuristics that trigger enterprise_agent for short “business proposal” phrases and finance_agent for short stock queries. These rules use len(normalized) < 100 / < 80. Short user prompts that include words like “proposal” or “financials” may be mis-classified as simple and bypass LLM planning. (See _try_fast_path_routing.)

Effect: Some complex requests still hit the fast path and get simplified single-agent plans.

B. Over-aggressive post-processing filters

After LLM (or fallback), _post_process_steps may remove agents or enforce single-agent mode if prompt_is_short and prompt_is_simple. The method also contains a business-proposal filter that removes finance_agent unless real market data explicitly requested (_is_business_proposal_query). (See the # For business proposals/strategy docs block.)

Effect: Even when the LLM requested finance_agent, _post_process_steps can remove it if it decides this is a proposal. That explains finance agent being stripped out.

C. Multiple overlapping heuristics and string-keyword rules

The planner uses many internal predicates _prompt_mentions_finance, _is_pure_finance_query, _prompt_mentions_enterprise, _requires_multi_agent, etc. These are keyword-heavy, have overlapping vocabularies, and some contain ambiguous tokens (e.g., "market", "revenue") used by several domains. (Search these helpers.)

Effect: Ambiguity leads to flip-flop decisions: sometimes finance is added, sometimes removed; creative agent triggers when not intended if keywords slip in.

D. Single-agent enforcement fallback for multi-agent outputs

There is a final “single-agent enforcement” block which quietly picks a single agent in many multi-agent cases unless _requires_multi_agent(prompt) returns True. That function uses length > 200 and many explicit triggers; but many realistic multi-step prompts are shorter than 200 chars and still need multiple agents.

Effect: Multi-agent plans get collapsed to a single agent for many real-world multi-part prompts.

E. LLM plan parsing & sanitization could hide LLM intent

The planner requires the LLM to produce strict JSON. If the LLM includes extra fields or text around the JSON, _parse_json tries to extract JSON but then _sanitize_plan_payload strips unknown top-level and step-level fields. This is safe, but it also removes extra contextual data LLM might have included (like a metadata.domains array) that could help routing.

Effect: The post-LLM loss of extra signals reduces the planner’s ability to confirm the LLM’s intent, causing the heuristic filters to dominate.

solution:
Introduce "soft" vs "hard" rules set

Convert many keyword rules into soft-scores rather than binary triggers. Compute domain scores (enterprise_score, finance_score, research_score) and make decision by thresholds and relative magnitudes, with LLM plan as tiebreaker.

Preserve extra metadata from LLM

Don’t fully strip unknown fields in _sanitize_plan_payload. Allow a metadata._raw or metadata.agent_intent to survive so post-processing can consult LLM’s own reasoning. (Sanitize still necessary for safety — keep a whitelist, but include metadata["llm_notes"]=...)

Enforce multi-step generation contract

Change planning contract to require the LLM to produce both steps and an explicit justification per step (short text). Use that text to decide whether the agent is relevant; this reduces hallucinated agent selection. Gatekeeper can ensure the justification is present for each step.

Refine requires_multi_agent heuristics

Lower the 200-character rule and build more nuanced rules: look for connectors ("and", "also", "then", ", then", "as well as") and count domain keywords. Or better: call a small deterministic classifier LLM (Phi-3 Mini) to decide whether multi-agent is required.

4) Specific code locations to change (lines / helpers) 

llm_planner

_try_fast_path_routing — make thresholds stricter and consider adding additional negative checks (e.g., presence of multiple domain keywords).

_post_process_steps — change single-agent enforcement block (the large block starting # Single-Agent Mode: ONLY for very short, clear single-domain intents) to be more conservative and consult validated_plan confidences before stripping agents.

_is_business_proposal_query — change behavior so it does not remove finance_agent automatically; instead set a "proposal-preference" flag but still keep finance if finance keywords present.

_requires_multi_agent — refine triggers and domain_counts logic; consider returning True if domain_counts >= 2 or refer to a classifier call.

_sanitize_plan_payload — allow carrying metadata._raw_llm_notes or preserve steps[*].justification if present from LLM.

5) Example small patch suggestions
A. Make fast-path very conservative
# inside _try_fast_path_routing
# change thresholds from 100/80 -> 40
is_simple_proposal = (
    len(normalized) < 40 and ...
)
is_simple_stock_query = (
    len(normalized) < 40 and ...
)

B. Avoid removing finance for proposals unless absent of finance keywords

Replace the block:

if self._is_business_proposal_query(prompt):
    proposal_agents = [s for s in updated_steps if s.agent in {"enterprise_agent", "creative_agent"}]
    removed_agents = [s for s in updated_steps if s.agent not in {"enterprise_agent", "creative_agent"}]
    ...


with:

if self._is_business_proposal_query(prompt) and not self._prompt_mentions_finance(prompt):
    # only remove finance if finance NOT explicitly mentioned
    ...

C. Respect LLM step confidence

Before trimming to single agent in final check:

# compute average step confidence
avg_conf = sum((s.confidence or 0.0) for s in updated_steps)/len(updated_steps)
if avg_conf > 0.8 and len(updated_steps)>1:
    # trust LLM multi-agent decision
    keep all
else:
    # then apply single-agent fallback

6) Short checklist / prioritized roadmap to implement today

Tighten fast-path thresholds. (Quick — < 30 min)

Prevent unconditional removal of finance in proposal block. (Quick — < 30 min)

Add LLM-confidence check before enforcing single-agent. (Moderate — 1–2 hrs)

Add logs that include which heuristic removed which agent and why (if not already detailed). (Quick)

Longer-term: refactor heuristics into weighted domain scores or call a small classifier LLM to decide multi-agent need. (Medium — a day or two)

Update the planning contract to preserve step justifications for better auditability (Medium).